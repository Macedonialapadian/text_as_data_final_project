{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_2Om_StXcJj"
   },
   "source": [
    "# Day 3: Fine-Tuning a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YLrDQqiNc-9"
   },
   "source": [
    "## Classification Models\n",
    "\n",
    "When looking to train a classification models using a Transformers-based architecture, there are a number of steps to follow (and steps within steps). The first step is to train/test/validate and fine-tune the model using your labeled data; once you are happy with the performance, we are ready to train a final model; and, finally, we use that model to classify as much data as we want (sort of). Let's start...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epl2dyBRtWGD"
   },
   "source": [
    "### 1. Fine-Tuning a Model\n",
    "\n",
    "We first want to train/test/validate and fine-tune a model using our labeled data. We will divide our labeled data into a training sample (used to train our model) and a testing sample (used to test the performance of the model). Additionally, I will show you how to use cross-validation, to increase confidence in your performance metrics. In this step we can also adjust different hyper-parameters that can ultimately help with performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLCDnMiwTBeo"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "### NO NEED TO CHANGE ANYTHING HERE UNTIL YOU GET THE HANG OF IT ###\n",
    "####################################################################\n",
    "\n",
    "# We will need to import a whole bunch of libraries:\n",
    "\n",
    "# First, our Roberta Tokenizer and our Roberta Classifier:\n",
    "# from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "# If you wanted to use another model, such as XLM-RoBERTa, the code would look something like this:\n",
    "# from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "# More generally, however, you can use the AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Some other libraries to adjust hyper-parameters:\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Torch: A Tensor library like NumPy, with strong GPU support\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# For performance statistics I like to use sklearn:\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report, precision_score, recall_score\n",
    "\n",
    "# And the rest to help:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "def good_update_interval(total_iters, num_desired_updates):\n",
    "    exact_interval = total_iters / num_desired_updates\n",
    "    order_of_mag = len(str(total_iters)) - 1\n",
    "    round_mag = order_of_mag - 1\n",
    "    update_interval = int(round(exact_interval, -round_mag))\n",
    "    if update_interval == 0:\n",
    "        update_interval = 1\n",
    "    return update_interval\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2252si7jqDI"
   },
   "source": [
    "Our labeled data is of news articles coded into five categories of documents. The five categories are politics, sport, tech, entertainment and business. For the purposes of this example I have recoded all political articles as 1 and taken a random sample of the rest, an recoded them as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "TsggRPQHTWIi",
    "outputId": "cc7e5f8d-bbcf-4dee-fb52-6be08885edd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label Label_Cat  \\\n",
      "0  Budget to set scene for election\\n \\n Gordon B...      0  Politics   \n",
      "1  Army chiefs in regiments decision\\n \\n Militar...      0  Politics   \n",
      "2  Howard denies split over ID cards\\n \\n Michael...      0  Politics   \n",
      "3  Observers to monitor UK election\\n \\n Minister...      0  Politics   \n",
      "4  Kilroy names election seat target\\n \\n Ex-chat...      0  Politics   \n",
      "\n",
      "   Label_Politics  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_Politics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "Label_Politics\n",
       "0    420\n",
       "1    417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your labeled data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/svallejovera/iesp-uerj/main/politics_sample.csv\")\n",
    "\n",
    "# Check your data\n",
    "print(data.head(5))\n",
    "\n",
    "# Set the main variable to be used for classification:\n",
    "var = 'Label_Politics' ## <- CHANGE THIS BY LOOKING AT YOUR LABELED DATASET!!!\n",
    "data[var].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "DHbW7ZPbcmKe",
    "outputId": "2d502824-eb3a-4fcf-ec99-42ca71159416"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "label\n",
       "0    420\n",
       "1    417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "### NO NEED TO CHANGE ANYTHING HERE UNTIL YOU GET THE HANG OF IT ###\n",
    "####################################################################\n",
    "\n",
    "# Re index and change type/name:\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data[\"label\"] = data[var].astype('category')\n",
    "data[\"label\"] = data[\"label\"].cat.codes\n",
    "\n",
    "# Check that it worked\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "ff4ac9f0ba344b48b8234e87bc95f41a",
      "9da53ed85b0f44df8dd39a2193ef436c",
      "dc60d595a2ea4f8caa3178ff3cfbdc6c",
      "d5cd0781cd0145ae9fcbb70f4598138e",
      "ec38fdfed1f749a6b3264d7efb42aea8",
      "d8a0e3b103c1497fa18d745c0e83cec4",
      "69c1c2c91390452bab8b94198ab67774",
      "23cc855f089b4ddebabc6274e0f455ff",
      "b63e72b5b0e345e69607587a85cd4904",
      "391c6585c2264820a02585d980823b7d",
      "487719303f494f13a501e918744dc3ec",
      "c5c09764da344db990b00bf477731d05",
      "d05022c9201e480883208575747446b9",
      "725c85ea38aa422b9893e620e2bab6dc",
      "7e555b5b558d4395b2133a0960c0156c",
      "9265ae3159bb4a16b9023c4a3e3d957e",
      "d9c9da4e0188446d91cb871b514fba60",
      "63951e4e3cf54fb19d4872ccf829e5e1",
      "0c00f48246fa43019750e55fc00bdc71",
      "90466afcca22435dbf00c81a83417f68",
      "fee6f3d49082401bada6ecce0a421a37",
      "bf29ab36880b45fda4702ede81526cb9",
      "9f54f7c8aaad4e2889aaa57e91e4210c",
      "09a2b42ae1d74c9895be16660128b987",
      "53216c646ff04c11ad56e69acf28f60d",
      "eb6f3962465e46beb532abeec20bd7b7",
      "d362abccded04398a832024fbce01ab6",
      "19f16ad108044900a381649e391e27f4",
      "f0c38ae42b344bea927a0a1559f2e860",
      "2edcc54204ee40579c36f43c3e02e956",
      "d33955221c02488f9f3a05719d532a40",
      "9cd9b963b87041c5bc7e2e2a16305e33",
      "9a09be8b82614da9b8b1beddc5bf8072",
      "c4a2a64204c94f33ae21f40ca3da142b",
      "0a4a34d5f1b84749aed602789b142038",
      "b91f113e4637408e876e9b9dafc04dcb",
      "ccf572f3ceb045128af564b61852a743",
      "8dcb59fe5e6a4bff833f9759be7f08e5",
      "1b2bf601ce3a41eb8f1ae589b5b569e3",
      "d28625b5877d40c4b20e10a6343a756d",
      "4a4081b404904121a51041cebc838437",
      "24498d13bbb844b6be8da70662fa1d89",
      "4aa975ed8793424fbfa32a99de1409fc",
      "33246a993c5a45b8ada7ff42559f9652",
      "6105b4a41f684fabad7c4cc7b5c753a0",
      "0ab192a7868a456a92328a48bf727188",
      "f0d879ac4244413383061d1e1c525050",
      "73111caee1814b6283812dc56273b2b1",
      "e4a98a1836ce4983ae21b1c6633b1599",
      "acdfcb8b120c4170a9b85c6de7ee6d72",
      "a2967b942e624c83a2deea513b8b1564",
      "171d3b8e7ff74f59b5d27e6fa3c38c0d",
      "536eb6d0262c40b4b022f96c4089e0db",
      "ca6c858450da487a93ea050d19d8724a",
      "2e40f8ec12cc42e7b327bfa51946af47"
     ]
    },
    "id": "L2hm_g1ic6bK",
    "outputId": "8fc92ac7-6a47-4a65-d170-171c4e6fa40b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4ac9f0ba344b48b8234e87bc95f41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c09764da344db990b00bf477731d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f54f7c8aaad4e2889aaa57e91e4210c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a2a64204c94f33ae21f40ca3da142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6105b4a41f684fabad7c4cc7b5c753a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       837 comments\n",
      "   Min length: 112 tokens\n",
      "   Max length: 5,390 tokens\n",
      "Median length: 487.0 tokens\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "### YOU NEED TO CHANGE THIS TO THE NAME OF YOUR COLUMN WITH THE TEXT!!! ###\n",
    "###########################################################################\n",
    "\n",
    "###########################################################################\n",
    "### If using a different model, here is where you would change it...... ###\n",
    "###########################################################################\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "# Record the length of each sequence (in terms of BERT tokens).\n",
    "\n",
    "# Choose tokenizer: \"roberta-base\" (could be 'roberta-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", do_lower_case=True)\n",
    "\n",
    "# If you were using some other model, like XLM-RoBERTa, then the code would look\n",
    "# something like this (but then everything else is pretty much the same):\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large-finetuned-conll02-spanish\", do_lower_case=True)\n",
    "\n",
    "input_ids = []\n",
    "lengths = []\n",
    "for x, row in data.iterrows():\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        row['Text'], ## <- CHANGE THIS TO NAME OF YOUR TEXT COLUMN\n",
    "                        add_special_tokens = True,\n",
    "                   )\n",
    "    input_ids.append(encoded_sent)\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "print('{:>10,} comments'.format(len(input_ids)))\n",
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(np.median(lengths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lcJuPiwdlaU",
    "outputId": "91f95566-6142-439b-8b19-7e3d6b4f1999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 of 837 sentences (99.9%) in the training set are longer than 120 tokens.\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "### You can change the max length of the input to satisfy you computing power ###\n",
    "#################################################################################\n",
    "\n",
    "###########################################################################\n",
    "### YOU NEED TO CHANGE THIS TO THE NAME OF YOUR COLUMN WITH THE TEXT!!! ###\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "# We will trunctate the text input since BERT can only handle 512 tokens at a time\n",
    "# Also, the more tokens you have, the more memory your computer requires\n",
    "\n",
    "max_len = 120 # Only for the sake of this example\n",
    "\n",
    "num_truncated = np.sum(np.greater(lengths, max_len))\n",
    "num_sentences = len(lengths)\n",
    "prcnt = float(num_truncated) / float(num_sentences)\n",
    "print('{:,} of {:,} sentences ({:.1%}) in the training set are longer than {:} tokens.'.format(num_truncated, num_sentences, prcnt, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHhkda8Rdd2V"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "### YOU NEED TO CHANGE THIS TO THE NAME OF YOUR COLUMN WITH THE TEXT!!! ###\n",
    "###########################################################################\n",
    "\n",
    "# Decide on your max length\n",
    "max_len = 120 ## <- CHANGE THIS (if you want)!!!\n",
    "\n",
    "# Create tokenized data\n",
    "labels = []\n",
    "input_ids = []\n",
    "attn_masks = []\n",
    "\n",
    "for x, row in data.iterrows():\n",
    "    encoded_dict = tokenizer.encode_plus(row['Text'], ## <- CHANGE THIS TO NAME OF YOUR TEXT COLUMN\n",
    "                                              max_length=max_len,\n",
    "                                              padding='max_length',\n",
    "                                              truncation=True,\n",
    "                                              return_tensors='pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attn_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(row['label'])\n",
    "\n",
    "# Convert into tensor matrix.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attn_masks = torch.cat(attn_masks, dim=0)\n",
    "\n",
    "# Labels list to tensor.\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attn_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPtAL_kAeave"
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "### You can play with the parameters if you want...                           ###\n",
    "#################################################################################\n",
    "\n",
    "#########\n",
    "# Specify key model parameters here:\n",
    "model_name = \"roberta-base\" # <- The model you will choose. It has to match the tokenizer\n",
    "lr = 2e-5 # <- Learning rate... usually between 2e-5 and 2e-6\n",
    "epochs = 2 # <- No more than 5 or you will start overfitting\n",
    "batch_size = 8 # <- Best if multiple of 2^x... The more the better but also the more GPU\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlVRZVsrfSB0"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "### NO NEED TO CHANGE ANYTHING HERE UNTIL YOU GET THE HANG OF IT ###\n",
    "####################################################################\n",
    "\n",
    "seed_val = 6\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "torch.cuda.empty_cache() #Clear GPU cache if necessary\n",
    "\n",
    "training_stats = [] # Store training and validation loss, validation accuracy, and timings.\n",
    "fold_stats = []\n",
    "\n",
    "total_t0 = time.time() # Measure the total training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNnDfHY1ifJ3"
   },
   "source": [
    "To determine which hyperparameters to use and then to evaluate the performance of all Transformer models, we use cross-validation (CV). First, the data is divided into $k$ fixed subsets or chunks. In each fold (iteration of CV), one subset is held out from the training process and used to validate the model, while the rest of the chunks, the $k-1$ subsets, are then used to train the model. This process is repeated $k$ times using a different set of test data in each of the folds, and the performance metrics are averaged over all trials to get the approximate true out-of-sample accuracy of the model. If no `best' model is selected from the $k$ runs, there is no need to hold out a further chunk from the data for a true out-of-sample evaluation of performance. The intuition behind CV is to be sure that performance metrics are not affected by 'easy' or 'hard' breaks of the data (e.g., an easy test set might overestimate the accuracy of the model, while a hard test set might underestimate it).\n",
    "\n",
    "For our example, we will run two folds because of time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "19a170f2c22a4b8e8957489493c18417",
      "e6d69c37ffb0410590454f57634b81e3",
      "cdd44541f7854919a2aa5e0aec427d6d",
      "49222754fb5a439c9a74a185a4976305",
      "7ababb114ace4e6cbde96309564d2566",
      "b43922ef1bdb4a1fb77626fe28e91967",
      "407e6e7efe6d4ca4a57419d2d327af12",
      "6e9430fded264ed6954f56198ddd0d7b",
      "530016d49f1f4ddda0748efcb6c9ac6c",
      "0d79a05f9ca145e1936b4ae77c108003",
      "c67715101dc949a2a13c6cbfd35dfcc0"
     ]
    },
    "id": "zTN8twMlfaU5",
    "outputId": "b654c884-e284-40db-bd10-67ddf9f9c2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a170f2c22a4b8e8957489493c18417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.476\n",
      "  Training epoch took: 0:00:14\n",
      "  Training accuracy: 0.794\n",
      "\n",
      "Running test...\n",
      "RoBERTa Prediction accuracy: 0.971\n",
      "RoBERTa F1 accuracy: 0.971\n",
      "[[188  11]\n",
      " [  1 219]]\n",
      "  Test Loss: 0.077\n",
      "  Test took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.055\n",
      "  Training epoch took: 0:00:13\n",
      "  Training accuracy: 0.988\n",
      "\n",
      "Running test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa Prediction accuracy: 0.988\n",
      "RoBERTa F1 accuracy: 0.988\n",
      "[[195   4]\n",
      " [  1 219]]\n",
      "  Test Loss: 0.060\n",
      "  Test took: 0:00:06\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.500\n",
      "  Training epoch took: 0:00:13\n",
      "  Training accuracy: 0.749\n",
      "\n",
      "Running test...\n",
      "RoBERTa Prediction accuracy: 0.990\n",
      "RoBERTa F1 accuracy: 0.990\n",
      "[[219   2]\n",
      " [  2 195]]\n",
      "  Test Loss: 0.034\n",
      "  Test took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.046\n",
      "  Training epoch took: 0:00:13\n",
      "  Training accuracy: 0.986\n",
      "\n",
      "Running test...\n",
      "RoBERTa Prediction accuracy: 0.988\n",
      "RoBERTa F1 accuracy: 0.988\n",
      "[[220   1]\n",
      " [  4 193]]\n",
      "  Test Loss: 0.051\n",
      "  Test took: 0:00:06\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "### YOU NEED TO CHANGE THE NUMBER OF K runs and of N LABELS!!!!!!!!!!!! ###\n",
    "###########################################################################\n",
    "\n",
    "# ======================================== #\n",
    "#              CV Training                 #\n",
    "# ======================================== #\n",
    "\n",
    "# repeat 2 times\n",
    "\n",
    "k_folds = 2 # <- CHANGE THE NUMBER OF FOLDS!!!\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H%M')\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=train_subsampler)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler)\n",
    "\n",
    "    # Initiate model parameters for each fold\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2) # <- CHANGE THE NUMBER OF LABELS!!!\n",
    "\n",
    "####################################################################\n",
    "### NO NEED TO CHANGE ANYTHING ELSE UNTIL YOU GET THE HANG OF IT ###\n",
    "####################################################################\n",
    "\n",
    "    device = torch.device('cuda:0')\n",
    "    desc = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = lr, eps = 1e-6)\n",
    "    total_steps = (int(len(dataset)/batch_size)+1) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 10, num_training_steps = total_steps)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0 # Reset the total loss for this epoch.\n",
    "        model.train() # Put the model into training mode.\n",
    "        update_interval = good_update_interval( # Pick an interval on which to print progress updates.\n",
    "                    total_iters = len(train_dataloader),\n",
    "                    num_desired_updates = 10\n",
    "                )\n",
    "\n",
    "        predictions_t, true_labels_t = [], []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if (step % update_interval) == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed), end='\\r')\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            # Always clear any previously calculated gradients before performing a backward pass.\n",
    "            model.zero_grad()\n",
    "            # Perform a forward pass --returns the loss and the \"logits\"\n",
    "            loss = model(b_input_ids,\n",
    "                               attention_mask=b_input_mask,\n",
    "                               labels=b_labels)[0]\n",
    "            logits = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)[1]\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "            total_train_loss += loss.item()\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "            # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            optimizer.step()\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # Store predictions and true labels\n",
    "            predictions_t.append(logits)\n",
    "            true_labels_t.append(label_ids)\n",
    "\n",
    "        # Combine the results across all batches.\n",
    "        flat_predictions_t = np.concatenate(predictions_t, axis=0)\n",
    "        flat_true_labels_t = np.concatenate(true_labels_t, axis=0)\n",
    "        # For each sample, pick the label (0, 1) with the highest score.\n",
    "        predicted_labels_t = np.argmax(flat_predictions_t, axis=1).flatten()\n",
    "        acc_t = accuracy_score(predicted_labels_t, flat_true_labels_t)\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        print(\"  Training accuracy: {:.3f}\".format(acc_t))\n",
    "\n",
    "        if acc_t > 0.9 and epoch_i >= 3:\n",
    "            break\n",
    "\n",
    "        # TEST\n",
    "        # After the completion of each training epoch, measure our performance on our test set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running test...\")\n",
    "        t0 = time.time()\n",
    "        model.eval() # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "        total_eval_loss = 0\n",
    "        predictions, true_labels = [], []\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                loss = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)[0]\n",
    "                logits = model(b_input_ids,\n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)[1]\n",
    "            # Accumulate the test loss.\n",
    "            total_eval_loss += loss.item()\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # Store predictions and true labels\n",
    "            predictions.append(logits)\n",
    "            true_labels.append(label_ids)\n",
    "\n",
    "        # Combine the results across all batches.\n",
    "        flat_predictions = np.concatenate(predictions, axis=0)\n",
    "        flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "        # For each sample, pick the label (0, 1) with the highest score.\n",
    "        predicted_labels = np.argmax(flat_predictions, axis=1).flatten()\n",
    "        # Calculate the test accuracy.\n",
    "        val_accuracy = (predicted_labels == flat_true_labels).mean()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "        ov_acc = [accuracy_score(predicted_labels, flat_true_labels), recall_score(predicted_labels, flat_true_labels, average=\"macro\"), precision_score(predicted_labels, flat_true_labels, average=\"macro\"),f1_score(predicted_labels, flat_true_labels, average=\"macro\")]\n",
    "        f1 = list(f1_score(flat_true_labels,predicted_labels,average=None))\n",
    "        f1_temp = f1_score(flat_true_labels,predicted_labels,average=\"weighted\")\n",
    "        matrix = confusion_matrix(flat_true_labels,predicted_labels)\n",
    "        acc = list(matrix.diagonal()/matrix.sum(axis=1))\n",
    "        cr = pd.DataFrame(classification_report(pd.Series(flat_true_labels),pd.Series(predicted_labels), output_dict=True)).transpose().iloc[0:3, 0:2]\n",
    "        prec =list(cr.iloc[:,0])\n",
    "        rec = list(cr.iloc[:,1])\n",
    "\n",
    "        # Report the final accuracy for this test run.\n",
    "        print('RoBERTa Prediction accuracy: {:.3f}'.format(val_accuracy))\n",
    "        print('RoBERTa F1 accuracy: {:.3f}'.format(f1_temp))\n",
    "\n",
    "        # It is good practice to look at your confusion matrix\n",
    "        print(matrix)\n",
    "\n",
    "        # Measure how long the test run took.\n",
    "        test_time = format_time(time.time() - t0)\n",
    "        print(\"  Test Loss: {0:.3f}\".format(avg_val_loss))\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    fold_stats.append(\n",
    "        {\n",
    "            'fold': fold+1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Test Loss': avg_val_loss,\n",
    "            'Test Accur.': ov_acc[0],\n",
    "            'f1': [f1, ov_acc[3]],\n",
    "            'prec': [prec, ov_acc[2]],\n",
    "            'rec': [rec, ov_acc[1]]\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yidu9SRccxOj"
   },
   "source": [
    "\n",
    "\n",
    "* **Validation/Test Loss ≫ Training Loss → Overfitting**\n",
    "  The model has memorized the training data but fails to generalize.\n",
    "\n",
    "* **Validation/Test Loss > Training Loss → Some Overfitting**\n",
    "  This is expected; usually indicates the model is learning well.\n",
    "\n",
    "* **Validation/Test Loss < Training Loss → Some Underfitting**\n",
    "  The model isn’t fitting the training data enough, often a sign that it’s too simple.\n",
    "\n",
    "* **Validation/Test Loss ≪ Training Loss → Underfitting**\n",
    "  The model is too weak to capture the patterns in the data.\n",
    "\n",
    "**Goal**: Minimize **validation/test loss**.\n",
    "A *little* overfitting is almost always desirable — it means the model is fitting training data well while still generalizing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-9ooiGbkat7"
   },
   "source": [
    "We can now get some performance stat to see how we did. You can check the meaning of each stat, how to interpret them, and when to use them, in scholarly journal [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall), or check out [this paper](https://d1wqtxts1xzle7.cloudfront.net/37219940/5215ijdkp01-libre.pdf?1428316763=&response-content-disposition=inline%3B+filename%3DA_REVIEW_ON_EVALUATION_METRICS_FOR_DATA.pdf&Expires=1709137264&Signature=f3EFHnlTZXa38ug6~VBumSZrfe9ECAyMUh04CNTzYnXEsVaJS3T12eNPbu7iNP~z3DSTTJ2NAV845v50XBe8Sjm7AylacfjGxcQ8YqaDsMulhkCV8c-JtTrWaLILlSUzbQp9M5Md3ubChx5Y9xkBp~s~XlecEEu9B5QEOjyr2aiZRA6gz98crSv0VKKV2ow986UxoSaWZgaYPmTsTrWU2EN3-0S1~OyO9tf2eFqbb3jUwOl15vX1rzzoG9lcpqbURB0eGMqPlXoWPHYBAlGmvUJOGxfkz15VpCxYtg-RoL5IYJONHlkV8GDWXntOm4WdY-ZIcgF3f3c7XhpDzgzvGw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31jx1KtkdY87",
    "outputId": "0ad1b6a4-4ea8-4065-b510-d150f24120d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold': 1,\n",
       "  'Training Loss': 0.0548539227061413,\n",
       "  'Test Loss': 0.05998427368028371,\n",
       "  'Test Accur.': 0.9880668257756563,\n",
       "  'f1': [[np.float64(0.9873417721518988), np.float64(0.9887133182844243)],\n",
       "   0.9880275452181615],\n",
       "  'prec': [[0.9948979591836735, 0.9820627802690582, 0.9880668257756563],\n",
       "   0.9876770214709913],\n",
       "  'rec': [[0.9798994974874372, 0.9954545454545455, 0.9880668257756563],\n",
       "   0.9884803697263659]},\n",
       " {'fold': 2,\n",
       "  'Training Loss': 0.045914599116241454,\n",
       "  'Test Loss': 0.05121823352814283,\n",
       "  'Test Accur.': 0.9880382775119617,\n",
       "  'f1': [[np.float64(0.9887640449438202), np.float64(0.9872122762148338)],\n",
       "   0.987988160579327],\n",
       "  'prec': [[0.9821428571428571, 0.9948453608247423, 0.9880382775119617],\n",
       "   0.9875852722971266],\n",
       "  'rec': [[0.995475113122172, 0.9796954314720813, 0.9880382775119617],\n",
       "   0.9884941089837997]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzAkqVTpjXC1"
   },
   "outputs": [],
   "source": [
    "politics_stats = []\n",
    "politics_stats.append(\n",
    "    {\n",
    "        'Model': model_name,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "\n",
    "        '0_f1': np.mean([x['f1'][0][0] for x in fold_stats ]),\n",
    "        '1_f1': np.mean([x['f1'][0][1] for x in fold_stats ]),\n",
    "\n",
    "        'overall_mean_f1': np.mean([x['f1'][1] for x in fold_stats ]),\n",
    "        'overall_mean_f1_sd': np.std([x['f1'][1] for x in fold_stats ]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgslMBt8nxrC",
    "outputId": "007bd96f-d087-4608-975b-b84961672b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'Training Loss': 0.0548539227061413, 'Test Loss': 0.05998427368028371, 'Test Accur.': 0.9880668257756563, 'f1': [[np.float64(0.9873417721518988), np.float64(0.9887133182844243)], 0.9880275452181615], 'prec': [[0.9948979591836735, 0.9820627802690582, 0.9880668257756563], 0.9876770214709913], 'rec': [[0.9798994974874372, 0.9954545454545455, 0.9880668257756563], 0.9884803697263659]}, {'fold': 2, 'Training Loss': 0.045914599116241454, 'Test Loss': 0.05121823352814283, 'Test Accur.': 0.9880382775119617, 'f1': [[np.float64(0.9887640449438202), np.float64(0.9872122762148338)], 0.987988160579327], 'prec': [[0.9821428571428571, 0.9948453608247423, 0.9880382775119617], 0.9875852722971266], 'rec': [[0.995475113122172, 0.9796954314720813, 0.9880382775119617], 0.9884941089837997]}]\n"
     ]
    }
   ],
   "source": [
    "print(fold_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mq72uw65n6SF",
    "outputId": "19c02ba0-77c8-48db-8b94-16d5493f03cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Model': 'roberta-base', 'lr': 2e-05, 'epochs': 2, 'batch_size': 8, '0_f1': np.float64(0.9880529085478595), '1_f1': np.float64(0.987962797249629), 'overall_mean_f1': np.float64(0.9880078528987443), 'overall_mean_f1_sd': np.float64(1.9692319417230486e-05)}]\n"
     ]
    }
   ],
   "source": [
    "print(politics_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ5OduZVoCPq"
   },
   "source": [
    "### 2. Final Model\n",
    "\n",
    "AMAZEBALLZ!! Ok, now that we know that our model is the shit, we can use ALL the data to train a final model that we can then use to classify whatever (english news) corpus we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUpCVEMIobwu",
    "outputId": "1b11ac8f-06bb-44d0-f5d2-0f4d785cdaf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.220\n",
      "  Training epoch took: 0:00:28\n",
      "  Training accuracy: 0.915\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.031\n",
      "  Training epoch took: 0:00:28\n",
      "  Training accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "### YOU NEED TO CHANGE THE NUMBER OF N LABELS!!!!!!!!!!!!               ###\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "# ======================================== #\n",
    "#               Training                   #\n",
    "# ======================================== #\n",
    "\n",
    "timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H%M')\n",
    "\n",
    "# Define data loaders for training and testing data in this fold\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "                       dataset,\n",
    "                       batch_size=batch_size)\n",
    "\n",
    "# Initiate model parameters for each fold\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # <- CHANGE THE NUMBER OF LABELS!!!\n",
    "device = torch.device('cuda:0')\n",
    "desc = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = lr, eps = 1e-8)\n",
    "total_steps = (int(len(dataset)/batch_size)+1) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 3, num_training_steps = total_steps)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0 # Reset the total loss for this epoch.\n",
    "    model.train() # Put the model into training mode.\n",
    "    update_interval = good_update_interval( # Pick an interval on which to print progress updates.\n",
    "                    total_iters = len(train_dataloader),\n",
    "                    num_desired_updates = 10)\n",
    "\n",
    "    predictions_t, true_labels_t = [], []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if (step % update_interval) == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed), end='\\r')\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "        # Perform a forward pass --returns the loss and the \"logits\"\n",
    "        loss = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)[0]\n",
    "        logits = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)[1]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Store predictions and true labels\n",
    "        predictions_t.append(logits)\n",
    "        true_labels_t.append(label_ids)\n",
    "\n",
    "    # Combine the results across all batches.\n",
    "    flat_predictions_t = np.concatenate(predictions_t, axis=0)\n",
    "    flat_true_labels_t = np.concatenate(true_labels_t, axis=0)\n",
    "    # For each sample, pick the label (0, 1) with the highest score.\n",
    "    predicted_labels_t = np.argmax(flat_predictions_t, axis=1).flatten()\n",
    "    acc_t = accuracy_score(predicted_labels_t, flat_true_labels_t)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    print(\"  Training accuracy: {:.3f}\".format(acc_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LixxohyBprBT"
   },
   "outputs": [],
   "source": [
    "# Save it in wherever FOLDER you want to save it... (it will be heavy though)\n",
    "# model.save_pretrained('/my_models/political_news/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syumv6XBqHP0"
   },
   "source": [
    "### 3. Using the Model\n",
    "\n",
    "To use the model, we just need to load it (we already loaded it, but I leave the code for when this is not the case), and CLASSIFY!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w51POsyyphV-",
    "outputId": "f889bcb6-7cc5-45a1-f7c0-2939ec931507"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(1), 'Politics')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If this was a new session, then you would need to load the tokenizer again...\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", do_lower_case=True)\n",
    "\n",
    "# If you saved your model somewhere, this is how you would retrieve it...\n",
    "# my_model = AutoModelForSequenceClassification.from_pretrained('/my_models/political_news/', num_labels=2) ## <- CHANGE THE NUMBER OF LABELS\n",
    "device = torch.device(\"cpu\")\n",
    "my_model = model.to(device)\n",
    "\n",
    "# Now we put our model in evaluation form:\n",
    "my_model.eval()\n",
    "\n",
    "label_dict = {0: \"Not Politics\", 1: \"Politics\"}\n",
    "\n",
    "def predict(sentence):\n",
    "    sentence = tokenizer.encode_plus(sentence, return_tensors='pt')\n",
    "    outputs = my_model(sentence[\"input_ids\"], attention_mask=sentence[\"attention_mask\"])\n",
    "    outputs = outputs[0].detach().numpy()\n",
    "    predicted_label = np.argmax(outputs)\n",
    "    label = label_dict[predicted_label]\n",
    "    return predicted_label, label\n",
    "\n",
    "predict(\"Voters 'reject EU by two to one' British voters would reject the European constitution by two to one, according to a poll posing the question the government will put to the country.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unwADuzNw1gN",
    "outputId": "08822279-6a5c-4bfb-fe59-78220337c4c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), 'Not Politics')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Footy Headlines can leak the Real Madrid 24-25 home kit, as worn by Bellingham (mocked-up picture). It has a no-nonsense design in white and black, plus a subtle Houndstooth pattern.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgB9sLVwHzbW"
   },
   "source": [
    "And here is some code to loop everything neatly so you can pass your target corpus through your fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5rwD3GZHyh9",
    "outputId": "35281f3c-dfa4-42ef-cc28-029b76b3cca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence          label\n",
      "0  Russian Skating Star Is 'Lighthearted' At Prac...         Sports\n",
      "1  Pete Buttigieg Rejects Notion That Black Voter...      Political\n",
      "2  Jay Z Is Making A Movie And Docuseries Based O...  Entertainment\n",
      "3  See All The Looks From The 2018 Golden Globes ...  Entertainment\n",
      "4  Jimmy Fallon Calls Out Mystery Object Coming F...  Entertainment\n",
      "5  Samantha Bee Gets Candid About Dealing With Tw...  Entertainment\n",
      "6  Exes Bella Hadid And The Weeknd Spotted Kissin...  Entertainment\n",
      "7  LeBron James Says Orlando Shooting Puts Import...         Sports\n",
      "8  House Panel Calls New Postmaster General To Ex...      Political\n",
      "9  The Humble Honeybee Honeybees are incomparable...        Science\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load data\n",
    "df = pd.read_parquet(\"hf://datasets/Themira/en_si_news_classification_with_label_name/data/train_en-00000-of-00001.parquet\")\n",
    "df_sample = df.iloc[:500]\n",
    "print(df_sample.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Opy6ObRNxpxd",
    "outputId": "bb1d456f-9efc-4071-9040-e8d4c65ed2c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:22<00:00,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence          label  \\\n",
      "0  Russian Skating Star Is 'Lighthearted' At Prac...         Sports   \n",
      "1  Pete Buttigieg Rejects Notion That Black Voter...      Political   \n",
      "2  Jay Z Is Making A Movie And Docuseries Based O...  Entertainment   \n",
      "3  See All The Looks From The 2018 Golden Globes ...  Entertainment   \n",
      "4  Jimmy Fallon Calls Out Mystery Object Coming F...  Entertainment   \n",
      "5  Samantha Bee Gets Candid About Dealing With Tw...  Entertainment   \n",
      "6  Exes Bella Hadid And The Weeknd Spotted Kissin...  Entertainment   \n",
      "7  LeBron James Says Orlando Shooting Puts Import...         Sports   \n",
      "8  House Panel Calls New Postmaster General To Ex...      Political   \n",
      "9  The Humble Honeybee Honeybees are incomparable...        Science   \n",
      "\n",
      "  predicted_sentences  \n",
      "0   (0, Not Politics)  \n",
      "1   (0, Not Politics)  \n",
      "2   (0, Not Politics)  \n",
      "3   (0, Not Politics)  \n",
      "4   (0, Not Politics)  \n",
      "5   (0, Not Politics)  \n",
      "6   (0, Not Politics)  \n",
      "7   (0, Not Politics)  \n",
      "8   (0, Not Politics)  \n",
      "9   (0, Not Politics)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipython-input-2810038558.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['predicted_sentences'] = predicted_sentences\n"
     ]
    }
   ],
   "source": [
    "# Run corpus through model:\n",
    "predicted_sentences = []\n",
    "\n",
    "for i in tqdm(df_sample['sentence']):\n",
    "    pred_temp = predict(i)\n",
    "    predicted_sentences.append(pred_temp)\n",
    "\n",
    "df_sample['predicted_sentences'] = predicted_sentences\n",
    "print(df_sample.head(10))\n",
    "# df_sample.to_csv(r'pred_df_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuKuXDDyxF2M"
   },
   "source": [
    "Isn't that neat!! Now you can get a larger corpus, run it through the prediction model, and get your results.\n",
    "\n",
    "Is this the last step? **No**. You still need to do one more validation: out-of-sample validation. You want to make sure that the sample you used as a training set was representative of your corpus, or that your model is able to properly classify text beyond the training set. To do this, you get a random sample from your corpus (*unseen* by the algorithm), label it, classify it (using your model), and check performance. Here, you might also want to look at the confusion matrix to better understand how is the model behaving (e.g., what type of error is more common, what categories it is over/under-predicting, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctAlkkadPD6n",
    "outputId": "5bf7d4eb-2c85-4dfb-fe72-9159d1318088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[393   3]\n",
      " [ 99   5]]\n",
      "Accuracy:  0.796\n",
      "Precision: 0.625\n",
      "Recall:    0.04807692307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# confusion matrix\n",
    "y_true_num = np.where(df_sample['label']==\"Political\", 1, 0)\n",
    "\n",
    "# prediction\n",
    "y_pred = df_sample['predicted_sentences'].apply(lambda x: x[0])\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true_num, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# measures\n",
    "accuracy = accuracy_score(y_true_num, y_pred)\n",
    "precision = precision_score(y_true_num, y_pred)\n",
    "recall = recall_score(y_true_num, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:   \", recall)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09a2b42ae1d74c9895be16660128b987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19f16ad108044900a381649e391e27f4",
      "placeholder": "​",
      "style": "IPY_MODEL_f0c38ae42b344bea927a0a1559f2e860",
      "value": "vocab.json: 100%"
     }
    },
    "0a4a34d5f1b84749aed602789b142038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b2bf601ce3a41eb8f1ae589b5b569e3",
      "placeholder": "​",
      "style": "IPY_MODEL_d28625b5877d40c4b20e10a6343a756d",
      "value": "merges.txt: 100%"
     }
    },
    "0ab192a7868a456a92328a48bf727188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acdfcb8b120c4170a9b85c6de7ee6d72",
      "placeholder": "​",
      "style": "IPY_MODEL_a2967b942e624c83a2deea513b8b1564",
      "value": "tokenizer.json: 100%"
     }
    },
    "0c00f48246fa43019750e55fc00bdc71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d79a05f9ca145e1936b4ae77c108003": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "171d3b8e7ff74f59b5d27e6fa3c38c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19a170f2c22a4b8e8957489493c18417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6d69c37ffb0410590454f57634b81e3",
       "IPY_MODEL_cdd44541f7854919a2aa5e0aec427d6d",
       "IPY_MODEL_49222754fb5a439c9a74a185a4976305"
      ],
      "layout": "IPY_MODEL_7ababb114ace4e6cbde96309564d2566"
     }
    },
    "19f16ad108044900a381649e391e27f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b2bf601ce3a41eb8f1ae589b5b569e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23cc855f089b4ddebabc6274e0f455ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24498d13bbb844b6be8da70662fa1d89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e40f8ec12cc42e7b327bfa51946af47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2edcc54204ee40579c36f43c3e02e956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33246a993c5a45b8ada7ff42559f9652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "391c6585c2264820a02585d980823b7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "407e6e7efe6d4ca4a57419d2d327af12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "487719303f494f13a501e918744dc3ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49222754fb5a439c9a74a185a4976305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d79a05f9ca145e1936b4ae77c108003",
      "placeholder": "​",
      "style": "IPY_MODEL_c67715101dc949a2a13c6cbfd35dfcc0",
      "value": " 499M/499M [00:02&lt;00:00, 286MB/s]"
     }
    },
    "4a4081b404904121a51041cebc838437": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4aa975ed8793424fbfa32a99de1409fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530016d49f1f4ddda0748efcb6c9ac6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53216c646ff04c11ad56e69acf28f60d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2edcc54204ee40579c36f43c3e02e956",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d33955221c02488f9f3a05719d532a40",
      "value": 898823
     }
    },
    "536eb6d0262c40b4b022f96c4089e0db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6105b4a41f684fabad7c4cc7b5c753a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ab192a7868a456a92328a48bf727188",
       "IPY_MODEL_f0d879ac4244413383061d1e1c525050",
       "IPY_MODEL_73111caee1814b6283812dc56273b2b1"
      ],
      "layout": "IPY_MODEL_e4a98a1836ce4983ae21b1c6633b1599"
     }
    },
    "63951e4e3cf54fb19d4872ccf829e5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69c1c2c91390452bab8b94198ab67774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e9430fded264ed6954f56198ddd0d7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "725c85ea38aa422b9893e620e2bab6dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c00f48246fa43019750e55fc00bdc71",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_90466afcca22435dbf00c81a83417f68",
      "value": 481
     }
    },
    "73111caee1814b6283812dc56273b2b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca6c858450da487a93ea050d19d8724a",
      "placeholder": "​",
      "style": "IPY_MODEL_2e40f8ec12cc42e7b327bfa51946af47",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 7.26MB/s]"
     }
    },
    "7ababb114ace4e6cbde96309564d2566": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e555b5b558d4395b2133a0960c0156c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fee6f3d49082401bada6ecce0a421a37",
      "placeholder": "​",
      "style": "IPY_MODEL_bf29ab36880b45fda4702ede81526cb9",
      "value": " 481/481 [00:00&lt;00:00, 20.4kB/s]"
     }
    },
    "8dcb59fe5e6a4bff833f9759be7f08e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90466afcca22435dbf00c81a83417f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9265ae3159bb4a16b9023c4a3e3d957e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a09be8b82614da9b8b1beddc5bf8072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cd9b963b87041c5bc7e2e2a16305e33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da53ed85b0f44df8dd39a2193ef436c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8a0e3b103c1497fa18d745c0e83cec4",
      "placeholder": "​",
      "style": "IPY_MODEL_69c1c2c91390452bab8b94198ab67774",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9f54f7c8aaad4e2889aaa57e91e4210c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09a2b42ae1d74c9895be16660128b987",
       "IPY_MODEL_53216c646ff04c11ad56e69acf28f60d",
       "IPY_MODEL_eb6f3962465e46beb532abeec20bd7b7"
      ],
      "layout": "IPY_MODEL_d362abccded04398a832024fbce01ab6"
     }
    },
    "a2967b942e624c83a2deea513b8b1564": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acdfcb8b120c4170a9b85c6de7ee6d72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b43922ef1bdb4a1fb77626fe28e91967": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63e72b5b0e345e69607587a85cd4904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b91f113e4637408e876e9b9dafc04dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a4081b404904121a51041cebc838437",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24498d13bbb844b6be8da70662fa1d89",
      "value": 456318
     }
    },
    "bf29ab36880b45fda4702ede81526cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4a2a64204c94f33ae21f40ca3da142b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a4a34d5f1b84749aed602789b142038",
       "IPY_MODEL_b91f113e4637408e876e9b9dafc04dcb",
       "IPY_MODEL_ccf572f3ceb045128af564b61852a743"
      ],
      "layout": "IPY_MODEL_8dcb59fe5e6a4bff833f9759be7f08e5"
     }
    },
    "c5c09764da344db990b00bf477731d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d05022c9201e480883208575747446b9",
       "IPY_MODEL_725c85ea38aa422b9893e620e2bab6dc",
       "IPY_MODEL_7e555b5b558d4395b2133a0960c0156c"
      ],
      "layout": "IPY_MODEL_9265ae3159bb4a16b9023c4a3e3d957e"
     }
    },
    "c67715101dc949a2a13c6cbfd35dfcc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca6c858450da487a93ea050d19d8724a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccf572f3ceb045128af564b61852a743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa975ed8793424fbfa32a99de1409fc",
      "placeholder": "​",
      "style": "IPY_MODEL_33246a993c5a45b8ada7ff42559f9652",
      "value": " 456k/456k [00:00&lt;00:00, 3.76MB/s]"
     }
    },
    "cdd44541f7854919a2aa5e0aec427d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e9430fded264ed6954f56198ddd0d7b",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_530016d49f1f4ddda0748efcb6c9ac6c",
      "value": 498818054
     }
    },
    "d05022c9201e480883208575747446b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9c9da4e0188446d91cb871b514fba60",
      "placeholder": "​",
      "style": "IPY_MODEL_63951e4e3cf54fb19d4872ccf829e5e1",
      "value": "config.json: 100%"
     }
    },
    "d28625b5877d40c4b20e10a6343a756d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d33955221c02488f9f3a05719d532a40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d362abccded04398a832024fbce01ab6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5cd0781cd0145ae9fcbb70f4598138e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_391c6585c2264820a02585d980823b7d",
      "placeholder": "​",
      "style": "IPY_MODEL_487719303f494f13a501e918744dc3ec",
      "value": " 25.0/25.0 [00:00&lt;00:00, 1.07kB/s]"
     }
    },
    "d8a0e3b103c1497fa18d745c0e83cec4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c9da4e0188446d91cb871b514fba60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc60d595a2ea4f8caa3178ff3cfbdc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23cc855f089b4ddebabc6274e0f455ff",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b63e72b5b0e345e69607587a85cd4904",
      "value": 25
     }
    },
    "e4a98a1836ce4983ae21b1c6633b1599": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6d69c37ffb0410590454f57634b81e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b43922ef1bdb4a1fb77626fe28e91967",
      "placeholder": "​",
      "style": "IPY_MODEL_407e6e7efe6d4ca4a57419d2d327af12",
      "value": "model.safetensors: 100%"
     }
    },
    "eb6f3962465e46beb532abeec20bd7b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cd9b963b87041c5bc7e2e2a16305e33",
      "placeholder": "​",
      "style": "IPY_MODEL_9a09be8b82614da9b8b1beddc5bf8072",
      "value": " 899k/899k [00:00&lt;00:00, 12.8MB/s]"
     }
    },
    "ec38fdfed1f749a6b3264d7efb42aea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c38ae42b344bea927a0a1559f2e860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0d879ac4244413383061d1e1c525050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_171d3b8e7ff74f59b5d27e6fa3c38c0d",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_536eb6d0262c40b4b022f96c4089e0db",
      "value": 1355863
     }
    },
    "fee6f3d49082401bada6ecce0a421a37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff4ac9f0ba344b48b8234e87bc95f41a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9da53ed85b0f44df8dd39a2193ef436c",
       "IPY_MODEL_dc60d595a2ea4f8caa3178ff3cfbdc6c",
       "IPY_MODEL_d5cd0781cd0145ae9fcbb70f4598138e"
      ],
      "layout": "IPY_MODEL_ec38fdfed1f749a6b3264d7efb42aea8"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
